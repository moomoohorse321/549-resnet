"""
The following sccript is written with the help of Github Copilot (GPT-4.1 mini)
The printing and plotting is generated by Claude Opus-4.5, with the context being the implementation and our intent (plot / print). 
The code is debugged with the help of Claude Opus-4.5, with the context being error logs, intermediate plots and code snippets.
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision as tv
from torch.utils.data import DataLoader
from collections import OrderedDict
import argparse

def conv3x3(ic, oc, s=1):
    return nn.Conv2d(ic, oc, 3, stride=s, padding=1, bias=False)

class OptionA(nn.Module):
    """Identity shortcut with stride-2 spatial downsampling and zero-channel pad."""
    def __init__(self, in_c, out_c, stride):
        super().__init__()
        self.in_c, self.out_c, self.stride = in_c, out_c, stride
        self.delta_c = out_c - in_c
        assert self.delta_c >= 0, "OptionA expects out_c >= in_c"

    def forward(self, x):
        if self.stride == 2:
            x = x[:, :, ::2, ::2]
        if self.delta_c > 0:
            pad = torch.zeros(x.size(0), self.delta_c, x.size(2), x.size(3),
                              dtype=x.dtype, device=x.device)
            x = torch.cat([x, pad], dim=1)
        return x

class RBlock(nn.Module):
    """Residual basic block (ResNet v1)"""
    def __init__(self, in_c, out_c, stride=1):
        super().__init__()
        self.c1, self.b1 = conv3x3(in_c, out_c, stride), nn.BatchNorm2d(out_c)
        self.c2, self.b2 = conv3x3(out_c, out_c, 1), nn.BatchNorm2d(out_c)
        self.short = nn.Identity() if (stride == 1 and in_c == out_c) else OptionA(in_c, out_c, stride)

    def forward(self, x):
        y = F.relu(self.b1(self.c1(x)))
        y = self.b2(self.c2(y))
        y = y + self.short(x)
        return F.relu(y)

class PBlock(nn.Module):
    """Plain block (no residual add)"""
    def __init__(self, in_c, out_c, stride=1):
        super().__init__()
        self.c1, self.b1 = conv3x3(in_c, out_c, stride), nn.BatchNorm2d(out_c)
        self.c2, self.b2 = conv3x3(out_c, out_c, 1), nn.BatchNorm2d(out_c)

    def forward(self, x):
        x = F.relu(self.b1(self.c1(x)))
        x = F.relu(self.b2(self.c2(x)))
        return x

def make_layer(block, in_c, out_c, n, stride):
    layers = [block(in_c, out_c, stride)]
    layers += [block(out_c, out_c, 1) for _ in range(n - 1)]
    return nn.Sequential(*layers)

class CIFARNet(nn.Module):
    """depth = 6n+2"""
    def __init__(self, n, residual=True, num_classes=10):
        super().__init__()
        B = RBlock if residual else PBlock
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.stage1 = make_layer(B, 16, 16, n, 1)
        self.stage2 = make_layer(B, 16, 32, n, 2)
        self.stage3 = make_layer(B, 32, 64, n, 2)
        self.fc = nn.Linear(64, num_classes)
        
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1.)
                nn.init.constant_(m.bias, 0.)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.stage1(x)
        x = self.stage2(x)
        x = self.stage3(x)
        x = F.adaptive_avg_pool2d(x, 1).flatten(1)
        return self.fc(x)

def get_test_loader(batch_size=256, workers=2):
    tf_test = tv.transforms.Compose([
        tv.transforms.ToTensor(),
        tv.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])
    testset = tv.datasets.CIFAR10('./data', train=False, download=True, transform=tf_test)
    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=workers, pin_memory=True)
    return testloader

@torch.no_grad()
def eval_error(model, loader, device):
    """Returns error rate (%)"""
    model.eval()
    correct = total = 0
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        correct += (model(x).argmax(1) == y).sum().item()
        total += y.numel()
    return 100.0 * (1 - correct / total)

def count_parameters(model):
    """Count trainable parameters"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

MODEL_CONFIG = {
    'ResNet-20':   (3, True),
    'ResNet-32':   (5, True),
    'ResNet-44':   (7, True),
    'ResNet-56':   (9, True),
    'ResNet-110':  (18, True),
}

PAPER_RESNET_RESULTS = {
    'ResNet-20':   {'layers': 20,  'params': '0.27M', 'error': 8.75},
    'ResNet-32':   {'layers': 32,  'params': '0.46M', 'error': 7.51},
    'ResNet-44':   {'layers': 44,  'params': '0.66M', 'error': 7.17},
    'ResNet-56':   {'layers': 56,  'params': '0.85M', 'error': 6.97},
    'ResNet-110':  {'layers': 110, 'params': '1.7M',  'error': 6.43}, 
}

def format_params(num_params):
    if num_params < 1e6:
        return f"{num_params/1e6:.2f}M"
    elif num_params < 10e6:
        return f"{num_params/1e6:.1f}M"
    else:
        return f"{num_params/1e6:.1f}M"

def print_table6(results):
    print("\n" + "="*70)
    print("Table 6. Classification error on the CIFAR-10 test set.")
    print("All methods are with data augmentation.")
    print("="*70)
    
    # Header
    print(f"\n{'method':<20} {'# layers':<12} {'# params':<12} {'error (%)':<20}")
    print("-"*65)
    
    # Other methods from paper (hardcoded values - these are from other papers)
    print(f"{'Maxout [10]':<20} {'-':<12} {'-':<12} {'9.38':<20}")
    print(f"{'NIN [25]':<20} {'-':<12} {'-':<12} {'8.81':<20}")
    print(f"{'DSN [24]':<20} {'-':<12} {'-':<12} {'8.22':<20}")
    print(f"{'FitNet [35]':<20} {'19':<12} {'2.5M':<12} {'8.39':<20}")
    print(f"{'Highway [42, 43]':<20} {'19':<12} {'2.3M':<12} {'7.54 (7.72±0.16)':<20}")
    print(f"{'Highway [42, 43]':<20} {'32':<12} {'1.25M':<12} {'8.80':<20}")
    
    print("-"*65)
    
    # Our ResNet results (from actual evaluation)
    for model_name in ['ResNet-20', 'ResNet-32', 'ResNet-44', 'ResNet-56', 'ResNet-110']:
        if model_name in results:
            r = results[model_name]
            print(f"{'ResNet':<20} {r['layers']:<12} {r['params']:<12} {r['error']:.2f}")
        else:
            ref = PAPER_RESNET_RESULTS[model_name]
            print(f"{'ResNet':<20} {ref['layers']:<12} {ref['params']:<12} {'N/A (no ckpt)':<20}")
    
    print("="*70)
    print("\nNote: Maxout, NIN, DSN, FitNet, Highway results are from the paper (not evaluated).")
    print("      ResNet results are from evaluating your trained checkpoints.")

def print_comparison(results):
    """Print comparison between our results and paper results"""
    print("\n" + "="*70)
    print("COMPARISON: Our Results vs Paper Results")
    print("="*70)
    print(f"{'Model':<15} {'Our Error':<12} {'Paper Error':<12} {'Difference':<12}")
    print("-"*55)
    
    for model_name in ['ResNet-20', 'ResNet-32', 'ResNet-44', 'ResNet-56', 'ResNet-110']:
        if model_name in results:
            r = results[model_name]
            paper_err = PAPER_RESNET_RESULTS[model_name]['error']
            diff = r['error'] - paper_err
            print(f"{model_name:<15} {r['error']:<12.2f} {paper_err:<12.2f} {diff:+.2f}")
        else:
            print(f"{model_name:<15} {'N/A':<12} {'-':<12} {'-':<12}")
    
    print("="*70)
    print("\nNote: For ResNet-110, paper ran 5 times: best=6.43, mean±std=6.61±0.16")

def main():
    parser = argparse.ArgumentParser(description='Evaluate ResNet models and reproduce Table 6')
    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints',
                        help='Directory containing model checkpoints')
    parser.add_argument('--device', type=str, default='cuda',
                        help='Device to use (cuda or cpu)')
    args = parser.parse_args()
    
    device = args.device if torch.cuda.is_available() or args.device == 'cpu' else 'cpu'
    print(f"Using device: {device}")
    
    # Load test data
    print("Loading CIFAR-10 test set...")
    testloader = get_test_loader(batch_size=256, workers=2)
    
    # Evaluate each model
    results = OrderedDict()
    
    for model_name, (n, residual) in MODEL_CONFIG.items():
        checkpoint_path = os.path.join(args.checkpoint_dir, f"{model_name}.pth")
        
        if not os.path.exists(checkpoint_path):
            print(f"WARNING: Checkpoint not found: {checkpoint_path}")
            continue
        
        print(f"\nEvaluating {model_name}...")
        
        # Create model
        model = CIFARNet(n=n, residual=residual)
        
        # Load checkpoint
        state_dict = torch.load(checkpoint_path, map_location=device, weights_only=True)
        model.load_state_dict(state_dict)
        model.to(device)
        
        # Count parameters
        num_params = count_parameters(model)
        
        # Evaluate
        error = eval_error(model, testloader, device)
        
        # Store results
        depth = 6 * n + 2
        results[model_name] = {
            'layers': depth,
            'params': format_params(num_params),
            'params_raw': num_params,
            'error': error,
        }
        
        print(f"  Layers: {depth}")
        print(f"  Parameters: {num_params:,} ({format_params(num_params)})")
        print(f"  Test Error: {error:.2f}%")
    
    # Print Table 6
    print_table6(results)
    
    # Print comparison
    print_comparison(results)

if __name__ == "__main__":
    main()